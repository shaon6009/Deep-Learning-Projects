{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":2083498,"sourceType":"datasetVersion","datasetId":1249230}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"[https://www.kaggle.com/code/rakibulhasanshaon69/yoga-pose-detection/edit](http://)","metadata":{}},{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom PIL import Image, ImageFile\n\nimport tensorflow as tf\nfrom tensorflow.keras.models import Model, Sequential\nfrom tensorflow.keras.layers import (\n    Dense, Dropout, BatchNormalization, Conv2D, MaxPooling2D, Flatten,\n    GlobalAveragePooling2D, Input, Multiply, Reshape\n)\nfrom tensorflow.keras.optimizers import Adam, SGD\nfrom tensorflow.keras.losses import BinaryCrossentropy\nfrom tensorflow.keras.applications import ResNet101, EfficientNetB4\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.regularizers import l2\nimport tensorflow_hub as hub\nfrom tensorflow.keras.callbacks import TensorBoard","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-11-20T01:00:13.922593Z","iopub.execute_input":"2024-11-20T01:00:13.923354Z","iopub.status.idle":"2024-11-20T01:00:26.848008Z","shell.execute_reply.started":"2024-11-20T01:00:13.923316Z","shell.execute_reply":"2024-11-20T01:00:26.847367Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def clean_invalid_images(directory):\n    for root, _, files in os.walk(directory):\n        for file in files:\n            file_path = os.path.join(root, file)\n            try:\n                with Image.open(file_path) as img:\n                    img.verify()\n            except (IOError, SyntaxError):\n                print(f\"Removing corrupted file: {file_path}\")\n                os.remove(file_path)\n\n\ndata= \"/kaggle/input/yoga-pose-image-classification-dataset/dataset\"\nclasses= sorted([folder for folder in os.listdir(data) if os.path.isdir(os.path.join(data, folder))])\nclean_invalid_images(data)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-20T01:00:26.849405Z","iopub.execute_input":"2024-11-20T01:00:26.849856Z","iopub.status.idle":"2024-11-20T01:01:07.470354Z","shell.execute_reply.started":"2024-11-20T01:00:26.849827Z","shell.execute_reply":"2024-11-20T01:01:07.468871Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def visualize_images(data, classes, num_images=5):\n    plt.figure(figsize=(15, len(classes) * 3)) \n    \n    for idx, cls in enumerate(classes):\n        class_path = os.path.join(data, cls)\n        images = [os.path.join(class_path, img) for img in os.listdir(class_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n\n        for i, img_path in enumerate(images[:num_images]):\n            plt.subplot(len(classes), num_images, idx * num_images + i + 1)\n            img = Image.open(img_path)\n            plt.imshow(img)\n            plt.axis('off')\n            if i == 0:\n                plt.title(cls, fontsize=12)\n\n    plt.tight_layout()\n    plt.show()\nvisualize_images(data, classes, num_images=5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-20T01:01:07.471957Z","iopub.execute_input":"2024-11-20T01:01:07.472382Z","iopub.status.idle":"2024-11-20T01:01:48.224251Z","shell.execute_reply.started":"2024-11-20T01:01:07.472336Z","shell.execute_reply":"2024-11-20T01:01:48.222906Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for class_name in os.listdir(data):\n    class_path = os.path.join(data, class_name)\n    if os.path.isdir(class_path):\n        for image_name in os.listdir(class_path):\n            image_path = os.path.join(class_path, image_name)\n            with Image.open(image_path) as img:\n                print(f\"Image: {image_name}, Class: {class_name}, Shape: {img.size}\")\n            break  ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-20T01:01:48.225896Z","iopub.execute_input":"2024-11-20T01:01:48.226658Z","iopub.status.idle":"2024-11-20T01:01:48.431673Z","shell.execute_reply.started":"2024-11-20T01:01:48.226590Z","shell.execute_reply":"2024-11-20T01:01:48.430716Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"dataset = tf.keras.preprocessing.image_dataset_from_directory(\n    data,\n    image_size=(224, 224), \n    batch_size=32,  \n    label_mode='int'  #  'categorical' or 'binary' \n)\n#'categorical' ব্যবহার করবেন যদি one-hot encoding চাচ্ছেন (বিশেষত যখন আপনার মডেলটি categorical crossentropy loss ফাংশন ব্যবহার করবে)।\n#'binary' ব্যবহার করবেন যদি বাইনারি ক্লাসিফিকেশন করছেন (যেমন, 2টি ক্লাসের মধ্যে নির্বাচন)।\n#'int' ব্যবহার করবেন যদি মাল্টিক্লাস ক্লাসিফিকেশন করতে চান এবং লেবেলগুলি একটি সংখ্যা হিসেবে চান (যেমন, 0 থেকে 106)।\n\ndataset = dataset.map(lambda x, y: (x / 255.0, y))\n\niterator = iter(dataset)\nimages, labels = next(iterator)\nprint(images.shape, labels.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-20T01:01:48.435049Z","iopub.execute_input":"2024-11-20T01:01:48.435798Z","iopub.status.idle":"2024-11-20T01:01:51.872164Z","shell.execute_reply.started":"2024-11-20T01:01:48.435745Z","shell.execute_reply":"2024-11-20T01:01:51.871185Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# spliting data","metadata":{}},{"cell_type":"code","source":"train_size = int(len(dataset) * 0.75)\nval_size = int(len(dataset) * 0.15)\ntest_size = int(len(dataset) * 0.10)\nval_size","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-20T01:01:51.874453Z","iopub.execute_input":"2024-11-20T01:01:51.874787Z","iopub.status.idle":"2024-11-20T01:01:51.889421Z","shell.execute_reply.started":"2024-11-20T01:01:51.874752Z","shell.execute_reply":"2024-11-20T01:01:51.887405Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train = dataset.take(train_size) \nval = dataset.skip(train_size).take(val_size) \ntest = dataset.skip(train_size + val_size).take(test_size) ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-20T01:01:51.891346Z","iopub.execute_input":"2024-11-20T01:01:51.891874Z","iopub.status.idle":"2024-11-20T01:01:51.921381Z","shell.execute_reply.started":"2024-11-20T01:01:51.891834Z","shell.execute_reply":"2024-11-20T01:01:51.917531Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# EfficientNet","metadata":{}},{"cell_type":"code","source":"train_datagen = ImageDataGenerator(\n    rotation_range=30, width_shift_range=0.2, height_shift_range=0.2,\n    shear_range=0.2, zoom_range=0.2, horizontal_flip=True, fill_mode='nearest'\n)\n\ninput_tensor = Input(shape=(224, 224, 3))\nbase_model = EfficientNetB4(weights=\"imagenet\", include_top=False, input_tensor=input_tensor)\nbase_model.trainable = True  \n\nx = GlobalAveragePooling2D()(base_model.output)\nx = Dense(512, activation=\"relu\", kernel_regularizer=l2(0.01))(x)\nx = Dropout(0.5)(x)  \nx = Dense(107, activation=\"softmax\")(x) \n\nmodel = Model(inputs=base_model.input, outputs=x)\n\nmodel.compile(optimizer=SGD(learning_rate=1e-3, momentum=0.9, nesterov=True), loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\nmodel.summary()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-20T01:01:51.924415Z","iopub.execute_input":"2024-11-20T01:01:51.924798Z","iopub.status.idle":"2024-11-20T01:01:55.553906Z","shell.execute_reply.started":"2024-11-20T01:01:51.924756Z","shell.execute_reply":"2024-11-20T01:01:55.553028Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"logdir = 'logs/efficientnet_b4'\ntensorboard_callback = TensorBoard(log_dir=logdir, histogram_freq=1)\n\nhist = model.fit(\n    train,\n    epochs=20,\n    validation_data=val,\n    callbacks=[tensorboard_callback]\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-20T01:01:55.555190Z","iopub.execute_input":"2024-11-20T01:01:55.555539Z","iopub.status.idle":"2024-11-20T01:27:54.207166Z","shell.execute_reply.started":"2024-11-20T01:01:55.555503Z","shell.execute_reply":"2024-11-20T01:27:54.206443Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"fig = plt.figure()\nplt.plot(hist.history['accuracy'], color='teal', label='accuracy')\nplt.plot(hist.history['val_accuracy'], color='orange', label='val_accuracy')\nfig.suptitle('Accuracy', fontsize=20)\nplt.legend(loc=\"upper left\")\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.show()\n\nfig = plt.figure()\nplt.plot(hist.history['loss'], color='teal', label='loss')\nplt.plot(hist.history['val_loss'], color='orange', label='val_loss')\nfig.suptitle('Loss', fontsize=20)\nplt.legend(loc=\"upper left\")\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-20T01:27:54.208303Z","iopub.execute_input":"2024-11-20T01:27:54.208584Z","iopub.status.idle":"2024-11-20T01:27:54.654787Z","shell.execute_reply.started":"2024-11-20T01:27:54.208558Z","shell.execute_reply":"2024-11-20T01:27:54.653950Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# ResNet101","metadata":{}},{"cell_type":"code","source":"input_tensor = Input(shape=(224, 224, 3))\nbase_model = ResNet101(weights=\"imagenet\", include_top=False, input_tensor=input_tensor)\nbase_model.trainable = True\n\ngap = GlobalAveragePooling2D()(base_model.output)\nse = Dense(256, activation=\"relu\")(gap)\nse = Dense(base_model.output_shape[-1], activation=\"sigmoid\")(se)\nse = Reshape((1, 1, base_model.output_shape[-1]))(se)\nse = Multiply()([base_model.output, se])\nx = GlobalAveragePooling2D()(se)\nx = Dense(1024, activation=\"relu\", kernel_regularizer=l2(1e-4))(x)\nx = BatchNormalization()(x)\nx = Dropout(0.5)(x)\nx = Dense(107, activation=\"softmax\", kernel_regularizer=l2(1e-4))(x)\n\nmodel = Model(inputs=base_model.input, outputs=x)\nmodel.compile(optimizer=Adam(learning_rate=1e-4), loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\nmodel.summary()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-20T01:27:54.655836Z","iopub.execute_input":"2024-11-20T01:27:54.656084Z","iopub.status.idle":"2024-11-20T01:27:58.299029Z","shell.execute_reply.started":"2024-11-20T01:27:54.656060Z","shell.execute_reply":"2024-11-20T01:27:58.298284Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"logdir = 'logs'\ntensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir)\nhist = model.fit(train, epochs=20, validation_data=val, callbacks=[tensorboard_callback])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-20T01:27:58.300258Z","iopub.execute_input":"2024-11-20T01:27:58.300996Z","iopub.status.idle":"2024-11-20T02:00:35.907059Z","shell.execute_reply.started":"2024-11-20T01:27:58.300956Z","shell.execute_reply":"2024-11-20T02:00:35.906213Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"fig = plt.figure()\nplt.plot(hist.history['accuracy'], color='teal', label='accuracy')\nplt.plot(hist.history['val_accuracy'], color='orange', label='val_accuracy')\nfig.suptitle('Accuracy', fontsize=20)\nplt.legend(loc=\"upper left\")\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.show()\n\nfig = plt.figure()\nplt.plot(hist.history['loss'], color='teal', label='loss')\nplt.plot(hist.history['val_loss'], color='orange', label='val_loss')\nfig.suptitle('Loss', fontsize=20)\nplt.legend(loc=\"upper left\")\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-20T02:00:35.908966Z","iopub.execute_input":"2024-11-20T02:00:35.909415Z","iopub.status.idle":"2024-11-20T02:00:36.354364Z","shell.execute_reply.started":"2024-11-20T02:00:35.909373Z","shell.execute_reply":"2024-11-20T02:00:36.353472Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Vision Transformar(base)","metadata":{}},{"cell_type":"code","source":"# vit_model = hub.KerasLayer(\"https://tfhub.dev/sayakpaul/vit_b16_fe/1\", trainable=True)\n# input_tensor = Input(shape=(224, 224, 3))\n\n# x = vit_model(input_tensor)\n# x = Dense(1024, activation=\"relu\")(x)\n# x = BatchNormalization()(x)\n# x = Dropout(0.5)(x)  # Regularization\n# x = Dense(107, activation=\"softmax\")(x)\n\n# model = Model(inputs=input_tensor, outputs=x)\n\n# model.compile(optimizer=Adam(learning_rate=3e-5), loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n# model.summary()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-20T02:00:36.356573Z","iopub.execute_input":"2024-11-20T02:00:36.356845Z","iopub.status.idle":"2024-11-20T02:00:36.360815Z","shell.execute_reply.started":"2024-11-20T02:00:36.356818Z","shell.execute_reply":"2024-11-20T02:00:36.359857Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Vision Transformar(advance)","metadata":{}},{"cell_type":"code","source":"# import tensorflow_hub as hub\n# import tensorflow as tf\n# from tensorflow.keras.models import Model\n# from tensorflow.keras.layers import Dense, Dropout, BatchNormalization, Input, Multiply, Reshape\n# from tensorflow.keras.optimizers import Adam\n# from tensorflow.keras.regularizers import l2\n\n# vit_model = hub.KerasLayer(\"https://tfhub.dev/google/vit_base_patch16_224/1\", trainable=True)\n\n# input_tensor = Input(shape=(224, 224, 3))\n# x = vit_model(input_tensor)\n\n# se = Dense(512, activation=\"relu\")(x)\n# se = Dense(x.shape[-1], activation=\"sigmoid\")(se)\n# se = Multiply()([x, se])\n\n# x = Dense(1024, activation=\"relu\", kernel_regularizer=l2(1e-4))(se)\n# x = BatchNormalization()(x)\n# x = Dropout(0.5)(x)\n# x = Dense(512, activation=\"relu\", kernel_regularizer=l2(1e-4))(x)\n# x = BatchNormalization()(x)\n# x = Dropout(0.5)(x)\n# x = Dense(107, activation=\"softmax\", kernel_regularizer=l2(1e-4))(x)\n\n# model = Model(inputs=input_tensor, outputs=x)\n# model.compile(optimizer=Adam(learning_rate=3e-5), loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n# model.summary()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-20T02:00:36.361777Z","iopub.execute_input":"2024-11-20T02:00:36.362010Z","iopub.status.idle":"2024-11-20T02:00:36.374733Z","shell.execute_reply.started":"2024-11-20T02:00:36.361986Z","shell.execute_reply":"2024-11-20T02:00:36.373969Z"}},"outputs":[],"execution_count":null}]}